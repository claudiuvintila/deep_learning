{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/merlin/.virtualenvs/dl4cv/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras as k\n",
    "\n",
    "from keras.datasets import mnist\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# chestii de DL\n",
    "from keras.layers.core import Dense, Activation\n",
    "from keras.optimizers import SGD, RMSprop, Adam\n",
    "from keras.models import Sequential\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calea catre mnist:  /home/merlin/.virtualenvs/dl4cv/lib/python3.5/site-packages/keras/datasets/mnist.py\n"
     ]
    }
   ],
   "source": [
    "# calea catre fisierul mnist\n",
    "print(\"calea catre mnist: \",mnist.__file__)\n",
    "\n",
    "# ca sa avem toti aceleasi rezultate\n",
    "from numpy.random import seed\n",
    "seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Magic numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "reshaped = 28*28\n",
    "nb_hidden_neurons_per_layer = 100\n",
    "nb_classes = 10\n",
    "optim = Adam()   # Stochastic Gradient Descent\n",
    "b_size = 128\n",
    "epoch = 20\n",
    "valid_split = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyse the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train.shape:  (60000, 28, 28)\n",
      "y_train.shape:  (60000,)\n",
      "x_test.shape:  (10000, 28, 28)\n",
      "y_test.shape:  (10000,)\n"
     ]
    }
   ],
   "source": [
    "print(\"x_train.shape: \",x_train.shape)    # <- daca era vector len(x_train)\n",
    "print(\"y_train.shape: \",y_train.shape)\n",
    "print(\"x_test.shape: \",x_test.shape)\n",
    "print(\"y_test.shape: \",y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot some data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label:  9\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f4ef97bd748>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "index = 154\n",
    "plt.imshow(x_train[index])\n",
    "print(\"label: \",y_train[index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " In ce interval sunt datele"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min pixelilor:  0\n",
      "max pixelilor:  255\n"
     ]
    }
   ],
   "source": [
    "print(\"min pixelilor: \",np.min(x_train))\n",
    "print(\"max pixelilor: \", np.max(x_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unroll the vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train.shape:  (60000, 784)\n",
      "x_test.shape:  (10000, 784)\n"
     ]
    }
   ],
   "source": [
    "x_train = np.reshape(x_train, (x_train.shape[0],reshaped))\n",
    "x_test = np.reshape(x_test, (x_test.shape[0],reshaped))\n",
    "\n",
    "print(\"x_train.shape: \",x_train.shape)\n",
    "print(\"x_test.shape: \",x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensure Float and Normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min pixelilor:  0.0\n",
      "max pixelilor:  1.0\n"
     ]
    }
   ],
   "source": [
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "# normalize\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "print(\"min pixelilor: \",np.min(x_train))\n",
    "print(\"max pixelilor: \", np.max(x_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# One-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label:  3\n"
     ]
    }
   ],
   "source": [
    "print(\"label: \",y_train[12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np_utils.to_categorical(y_train, nb_classes)\n",
    "y_test = np_utils.to_categorical(y_test, nb_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label:  [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(\"label: \",y_train[12])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a Neral Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 100)               78500     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                1010      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 89,610\n",
      "Trainable params: 89,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(nb_hidden_neurons_per_layer, input_shape=(reshaped,)))\n",
    "model.add(Dense(nb_hidden_neurons_per_layer))\n",
    "model.add(Dense(nb_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# get some info\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer=optim, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/20\n",
      "48000/48000 [==============================] - 1s 29us/step - loss: 0.4120 - acc: 0.8804 - val_loss: 0.2914 - val_acc: 0.9199\n",
      "Epoch 2/20\n",
      "48000/48000 [==============================] - 1s 20us/step - loss: 0.3031 - acc: 0.9137 - val_loss: 0.2815 - val_acc: 0.9232\n",
      "Epoch 3/20\n",
      "48000/48000 [==============================] - 1s 18us/step - loss: 0.2888 - acc: 0.9192 - val_loss: 0.2950 - val_acc: 0.9165\n",
      "Epoch 4/20\n",
      "48000/48000 [==============================] - 1s 19us/step - loss: 0.2848 - acc: 0.9203 - val_loss: 0.2757 - val_acc: 0.9252\n",
      "Epoch 5/20\n",
      "48000/48000 [==============================] - 1s 17us/step - loss: 0.2783 - acc: 0.9210 - val_loss: 0.2829 - val_acc: 0.9227\n",
      "Epoch 6/20\n",
      "48000/48000 [==============================] - 1s 25us/step - loss: 0.2734 - acc: 0.9229 - val_loss: 0.2803 - val_acc: 0.9218\n",
      "Epoch 7/20\n",
      "48000/48000 [==============================] - 1s 19us/step - loss: 0.2713 - acc: 0.9241 - val_loss: 0.2774 - val_acc: 0.9257\n",
      "Epoch 8/20\n",
      "48000/48000 [==============================] - 1s 17us/step - loss: 0.2690 - acc: 0.9248 - val_loss: 0.2783 - val_acc: 0.9249\n",
      "Epoch 9/20\n",
      "48000/48000 [==============================] - 1s 18us/step - loss: 0.2670 - acc: 0.9249 - val_loss: 0.2795 - val_acc: 0.9246\n",
      "Epoch 10/20\n",
      "48000/48000 [==============================] - 1s 24us/step - loss: 0.2638 - acc: 0.9256 - val_loss: 0.2756 - val_acc: 0.9235\n",
      "Epoch 11/20\n",
      "48000/48000 [==============================] - 1s 19us/step - loss: 0.2606 - acc: 0.9267 - val_loss: 0.2842 - val_acc: 0.9236\n",
      "Epoch 12/20\n",
      "48000/48000 [==============================] - 1s 20us/step - loss: 0.2628 - acc: 0.9259 - val_loss: 0.2846 - val_acc: 0.9230\n",
      "Epoch 13/20\n",
      "48000/48000 [==============================] - 1s 20us/step - loss: 0.2568 - acc: 0.9283 - val_loss: 0.2711 - val_acc: 0.9258\n",
      "Epoch 14/20\n",
      "48000/48000 [==============================] - 1s 18us/step - loss: 0.2594 - acc: 0.9265 - val_loss: 0.2840 - val_acc: 0.9250\n",
      "Epoch 15/20\n",
      "48000/48000 [==============================] - 1s 23us/step - loss: 0.2579 - acc: 0.9281 - val_loss: 0.2874 - val_acc: 0.9226\n",
      "Epoch 16/20\n",
      "48000/48000 [==============================] - 1s 25us/step - loss: 0.2542 - acc: 0.9283 - val_loss: 0.2982 - val_acc: 0.9167\n",
      "Epoch 17/20\n",
      "48000/48000 [==============================] - 1s 20us/step - loss: 0.2539 - acc: 0.9281 - val_loss: 0.2874 - val_acc: 0.9217\n",
      "Epoch 18/20\n",
      "48000/48000 [==============================] - 1s 29us/step - loss: 0.2540 - acc: 0.9280 - val_loss: 0.2738 - val_acc: 0.9287\n",
      "Epoch 19/20\n",
      "48000/48000 [==============================] - 1s 29us/step - loss: 0.2539 - acc: 0.9289 - val_loss: 0.2820 - val_acc: 0.9231\n",
      "Epoch 20/20\n",
      "48000/48000 [==============================] - 1s 18us/step - loss: 0.2531 - acc: 0.9290 - val_loss: 0.2780 - val_acc: 0.9269\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train, batch_size=b_size, epochs=epoch, verbose=1, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictions on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 22us/step\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the score and accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score:  0.2945468997657299\n",
      "accuracy:  0.9222\n"
     ]
    }
   ],
   "source": [
    "print(\"score: \",score[0])\n",
    "print(\"accuracy: \",score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find examples where the algo failed"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "y_test => realitatea\n",
    "y_pred => nu il avem\n",
    "\n",
    "Comparam y_test cu y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = np.max(y_pred[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99952495"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.9210191e-07, 3.3515450e-14, 2.1387559e-07, 3.9731231e-04,\n",
       "       3.7352446e-08, 1.8131169e-06, 7.5809557e-13, 9.9952495e-01,\n",
       "       1.0034013e-06, 7.4384421e-05], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_test_prim.shape:  (784,)\n",
      "(1, 784)\n",
      "pred_prim:  [7]\n"
     ]
    }
   ],
   "source": [
    "# Plot\n",
    "x_test_prim = x_test[0]\n",
    "print(\"x_test_prim.shape: \",x_test_prim.shape)\n",
    "img_usable = np.expand_dims(x_test_prim, axis=0)\n",
    "print(img_usable.shape)\n",
    "pred_prim = model.predict_classes(img_usable)\n",
    "print(\"pred_prim: \",pred_prim)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 1., 0., 0.])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.9210191e-07, 3.3515450e-14, 2.1387559e-07, 3.9731231e-04,\n",
       "       3.7352446e-08, 1.8131169e-06, 7.5809557e-13, 9.9952495e-01,\n",
       "       1.0034013e-06, 7.4384421e-05], dtype=float32)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "puscat = np.where((np.argmax(y_pred, axis=1) != np.argmax(y_test, axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([   8,   18,   66,   73,  149,  193,  211,  217,  233,  241,  245,\n",
       "         247,  251,  259,  307,  318,  320,  321,  340,  344,  352,  359,\n",
       "         362,  381,  406,  412,  425,  435,  445,  448,  469,  478,  479,\n",
       "         488,  502,  507,  516,  528,  531,  536,  542,  543,  551,  565,\n",
       "         569,  578,  582,  583,  591,  613,  619,  629,  659,  684,  691,\n",
       "         692,  707,  717,  720,  728,  740,  741,  760,  791,  829,  830,\n",
       "         839,  844,  857,  877,  881,  882,  890,  898,  924,  939,  947,\n",
       "         950,  951,  956,  958,  965,  975,  999, 1003, 1012, 1014, 1017,\n",
       "        1028, 1032, 1033, 1039, 1044, 1068, 1082, 1107, 1112, 1114, 1128,\n",
       "        1152, 1181, 1182, 1191, 1192, 1194, 1198, 1200, 1204, 1206, 1217,\n",
       "        1226, 1228, 1232, 1233, 1234, 1242, 1243, 1247, 1253, 1256, 1283,\n",
       "        1289, 1299, 1310, 1319, 1325, 1326, 1337, 1364, 1378, 1393, 1410,\n",
       "        1413, 1429, 1433, 1435, 1444, 1463, 1466, 1467, 1494, 1500, 1522,\n",
       "        1525, 1527, 1530, 1549, 1553, 1559, 1569, 1581, 1587, 1609, 1626,\n",
       "        1634, 1637, 1640, 1678, 1681, 1686, 1695, 1696, 1709, 1717, 1722,\n",
       "        1737, 1751, 1754, 1772, 1773, 1774, 1790, 1800, 1813, 1828, 1850,\n",
       "        1855, 1865, 1878, 1899, 1901, 1903, 1917, 1938, 1941, 1952, 1970,\n",
       "        1973, 1981, 1984, 2001, 2004, 2016, 2035, 2040, 2043, 2044, 2053,\n",
       "        2063, 2068, 2070, 2098, 2109, 2118, 2125, 2129, 2130, 2131, 2135,\n",
       "        2138, 2152, 2182, 2186, 2189, 2192, 2198, 2215, 2224, 2266, 2272,\n",
       "        2291, 2293, 2298, 2299, 2325, 2369, 2371, 2380, 2381, 2387, 2393,\n",
       "        2395, 2400, 2406, 2408, 2422, 2423, 2425, 2426, 2433, 2450, 2460,\n",
       "        2473, 2488, 2514, 2526, 2534, 2542, 2545, 2556, 2559, 2560, 2573,\n",
       "        2574, 2582, 2586, 2598, 2607, 2610, 2635, 2648, 2654, 2668, 2670,\n",
       "        2684, 2698, 2720, 2721, 2730, 2740, 2751, 2760, 2770, 2771, 2780,\n",
       "        2810, 2825, 2832, 2836, 2850, 2863, 2866, 2896, 2905, 2906, 2919,\n",
       "        2921, 2925, 2927, 2930, 2945, 2953, 2970, 2977, 2995, 3005, 3060,\n",
       "        3073, 3100, 3102, 3106, 3110, 3115, 3117, 3130, 3136, 3145, 3157,\n",
       "        3166, 3183, 3189, 3206, 3240, 3246, 3260, 3269, 3280, 3323, 3329,\n",
       "        3330, 3333, 3336, 3369, 3394, 3405, 3414, 3432, 3436, 3468, 3473,\n",
       "        3475, 3490, 3503, 3520, 3533, 3549, 3550, 3558, 3559, 3565, 3567,\n",
       "        3573, 3574, 3575, 3597, 3599, 3604, 3620, 3629, 3674, 3681, 3685,\n",
       "        3709, 3716, 3718, 3749, 3751, 3757, 3758, 3763, 3764, 3767, 3776,\n",
       "        3780, 3796, 3801, 3808, 3811, 3817, 3818, 3821, 3833, 3836, 3838,\n",
       "        3846, 3850, 3853, 3855, 3869, 3876, 3893, 3902, 3906, 3926, 3941,\n",
       "        3943, 3946, 3951, 3952, 3962, 3968, 3984, 3985, 4000, 4007, 4017,\n",
       "        4063, 4065, 4072, 4075, 4076, 4078, 4086, 4121, 4131, 4140, 4145,\n",
       "        4152, 4154, 4156, 4163, 4176, 4180, 4201, 4205, 4211, 4212, 4224,\n",
       "        4228, 4238, 4248, 4256, 4265, 4269, 4271, 4289, 4300, 4302, 4306,\n",
       "        4313, 4315, 4317, 4330, 4341, 4344, 4355, 4356, 4359, 4369, 4374,\n",
       "        4405, 4427, 4433, 4435, 4440, 4454, 4461, 4463, 4497, 4498, 4500,\n",
       "        4504, 4523, 4534, 4540, 4547, 4548, 4552, 4571, 4575, 4583, 4601,\n",
       "        4615, 4639, 4640, 4656, 4671, 4731, 4736, 4740, 4743, 4751, 4753,\n",
       "        4761, 4785, 4807, 4808, 4814, 4823, 4828, 4837, 4852, 4874, 4876,\n",
       "        4879, 4880, 4886, 4888, 4890, 4915, 4918, 4939, 4950, 4952, 4956,\n",
       "        4966, 4981, 4990, 5001, 5068, 5078, 5086, 5140, 5176, 5183, 5210,\n",
       "        5217, 5288, 5299, 5311, 5331, 5409, 5495, 5523, 5569, 5594, 5608,\n",
       "        5617, 5620, 5623, 5634, 5642, 5676, 5734, 5735, 5746, 5749, 5757,\n",
       "        5821, 5835, 5842, 5852, 5862, 5874, 5887, 5888, 5891, 5912, 5913,\n",
       "        5922, 5936, 5937, 5955, 5957, 5972, 5973, 5985, 6023, 6030, 6035,\n",
       "        6042, 6043, 6045, 6059, 6065, 6071, 6081, 6083, 6091, 6093, 6101,\n",
       "        6109, 6111, 6157, 6166, 6168, 6172, 6173, 6227, 6304, 6324, 6347,\n",
       "        6391, 6400, 6421, 6425, 6426, 6480, 6505, 6532, 6542, 6555, 6560,\n",
       "        6564, 6568, 6571, 6572, 6573, 6574, 6576, 6577, 6587, 6597, 6598,\n",
       "        6603, 6625, 6632, 6643, 6651, 6706, 6721, 6740, 6744, 6746, 6755,\n",
       "        6769, 6775, 6783, 6785, 6796, 6847, 6885, 6919, 6926, 6988, 7061,\n",
       "        7094, 7107, 7121, 7130, 7216, 7220, 7265, 7304, 7338, 7432, 7434,\n",
       "        7441, 7451, 7459, 7472, 7481, 7498, 7505, 7525, 7539, 7545, 7565,\n",
       "        7637, 7691, 7797, 7800, 7812, 7821, 7822, 7839, 7842, 7847, 7850,\n",
       "        7851, 7856, 7857, 7858, 7859, 7870, 7886, 7888, 7899, 7900, 7905,\n",
       "        7917, 7918, 7921, 7928, 7945, 7990, 7999, 8020, 8047, 8062, 8072,\n",
       "        8091, 8094, 8095, 8183, 8196, 8198, 8245, 8246, 8253, 8272, 8273,\n",
       "        8277, 8279, 8318, 8332, 8426, 8453, 8456, 8457, 8493, 8509, 8520,\n",
       "        8522, 8523, 8639, 8863, 9007, 9009, 9010, 9015, 9019, 9024, 9036,\n",
       "        9044, 9045, 9046, 9054, 9061, 9071, 9112, 9168, 9209, 9214, 9245,\n",
       "        9280, 9303, 9309, 9316, 9422, 9446, 9465, 9482, 9544, 9554, 9560,\n",
       "        9587, 9594, 9617, 9624, 9634, 9642, 9643, 9679, 9692, 9698, 9700,\n",
       "        9713, 9716, 9719, 9729, 9732, 9740, 9741, 9744, 9745, 9749, 9764,\n",
       "        9767, 9768, 9770, 9777, 9779, 9792, 9793, 9811, 9832, 9839, 9840,\n",
       "        9858, 9877, 9883, 9888, 9891, 9892, 9893, 9901, 9905, 9925, 9926,\n",
       "        9941, 9943, 9944, 9959, 9970, 9980, 9982, 9986]),)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "puscat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_test_prim.shape:  (784,)\n",
      "(1, 784)\n",
      "pred_prim:  [7]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAADhNJREFUeJzt3X+s3fVdx/HXq125YEcnZVpvoIy1VGYHSWGXsgoBFDcYkpW5hFAJqQRXZkBHXBRkJqCJCaLbxMFI7qBZ0Q3QAKEZTMEbI5Jh6QWRwjosYLu1KS2zIwV1l7b37R/3y3JX7vmc2/Pre27fz0dyc8/5vr/f833ne/vq95zzOd/zcUQIQD6z6m4AQD0IP5AU4QeSIvxAUoQfSIrwA0kRfiApwg8kRfiBpN7Ty50d4YE4UnN7uUsglR/rf/R2jHk667YVftsXSrpN0mxJd0XELaX1j9Rcnenz29klgIINMTLtdVt+2m97tqQ7JH1C0lJJq2wvbfXxAPRWO6/5l0t6OSJejYi3Jd0naWVn2gLQbe2E/zhJP5h0f3u17KfYXmN71PboPo21sTsAndT1d/sjYjgihiJiaI4Gur07ANPUTvh3SFo46f7x1TIAM0A74d8oaYntD9o+QtJlktZ3pi0A3dbyUF9E7Ld9raR/1MRQ39qIeLFjnQHoqrbG+SPiUUmPdqgXAD3Ex3uBpAg/kBThB5Ii/EBShB9IivADSRF+ICnCDyRF+IGkCD+QFOEHkiL8QFKEH0iK8ANJEX4gKcIPJEX4gaQIP5AU4QeSIvxAUoQfSIrwA0kRfiApwg8kRfiBpAg/kBThB5Ii/EBShB9Iqq1Zem1vlfSmpAOS9kfEUCeawiFafmrD0t7Fc4ubLv3cC8X66fO2Fevf/P4ZxfquPfOK9ZLFf3WgvMLTm1p+bLQZ/sqvRMQPO/A4AHqIp/1AUu2GPyQ9ZvsZ22s60RCA3mj3af/ZEbHD9s9Letz29yLiickrVP8prJGkI/Uzbe4OQKe0deaPiB3V792SHpK0fIp1hiNiKCKG5mignd0B6KCWw297ru2j37kt6eOSym8dA+gb7TztXyDpIdvvPM43I+IfOtIVgK5zRPRsZ/M8P870+T3bX794z8Lji/Vtv3lCsf7Jy54s1j977Hca1gZnH1XcdlzjxfqsJk8O29m+2ba7DowV62s+/TvFemzM9zmADTGivbHH01mXoT4gKcIPJEX4gaQIP5AU4QeSIvxAUp24qu+w0Gw4bs/ZjevNLosdXri+WB9Xebh1lsojNxvHGg/nnfvY1cVt5245olhv16wVP2pYu2npI8VtL5n7RrH+8nXlf76LLy+W0+PMDyRF+IGkCD+QFOEHkiL8QFKEH0iK8ANJcUlvZeBffqFYf+CkxmPS7V4We87zlxbrP35kQbE+OPJ6w9qBzVuK29Zpx/W/XKz/++99pVh/eqz8+Yc/XXT6Ifc003FJL4CmCD+QFOEHkiL8QFKEH0iK8ANJEX4gqTTX82/5ypnF+ksnfbVYf+R/39ew9gcPXlHcdtEDbxXr85pMNT1PrxTrTSaynrGafY/B8oHefUblcMSZH0iK8ANJEX4gKcIPJEX4gaQIP5AU4QeSajrOb3utpIsl7Y6IU6pl8yXdL+lESVslXRoRjb+gvQdevXVFsf7Sb9xerN/xxuJi/fELPtywtmj7U8Vt0Zpm8xk0+x4FlE3nzP91SRcetOwGSSMRsUTSSHUfwAzSNPwR8YSkPQctXilpXXV7naRLOtwXgC5r9TX/gojYWd1+TVL5e6YA9J223/CLiS8BbPjizPYa26O2R/dprN3dAeiQVsO/y/agJFW/dzdaMSKGI2IoIobmaKDF3QHotFbDv17S6ur2akkPd6YdAL3SNPy275X0lKSTbW+3fZWkWyR9zPYWSb9W3QcwgzQd54+IVQ1KffUF/L905n8V682uDf/rkQuK9SXbNxxyT2hPs78Zn1FrD0cPSIrwA0kRfiApwg8kRfiBpAg/kNRh89XdBy6fXayf/OdXFesfuvPga5cOevxD7gjt4pLe7uLMDyRF+IGkCD+QFOEHkiL8QFKEH0iK8ANJHTbj/Pu37yjWF19erjOO33ufvOzJYr3ZJb3PjHHuagdHD0iK8ANJEX4gKcIPJEX4gaQIP5AU4QeSOmzG+dGnlp/asPTZY+8sbjquo4r1K9f9brF+gr5TrGfHmR9IivADSRF+ICnCDyRF+IGkCD+QFOEHkmo6zm97raSLJe2OiFOqZTdL+oyk16vVboyIR7vVJGauV65rPJ/C4OzyOP5Nu08r1k/4E8bx2zGdM//XJV04xfIvR8Sy6ofgAzNM0/BHxBOSytPZAJhx2nnNf63t522vtX1MxzoC0BOthv9OSYslLZO0U9IXG61oe43tUduj+zTW4u4AdFpL4Y+IXRFxICLGJX1N0vLCusMRMRQRQ3M00GqfADqspfDbHpx091OSXuhMOwB6ZTpDffdKOk/S+21vl3STpPNsL5MUkrZKurqLPQLogqbhj4hVUyy+uwu9YAb676tWFOt/+9HbG9bGNV7c9u8fO6tYX6SninWU8Qk/ICnCDyRF+IGkCD+QFOEHkiL8QFJ8dTeK9v/qR4r127/QeChPks4YaDzN9pIHri1uu+R6hvK6iTM/kBThB5Ii/EBShB9IivADSRF+ICnCDyTFOD+K/uyu4WL9tIHyZblffeOkhrUP/fHm4rYHilW0izM/kBThB5Ii/EBShB9IivADSRF+ICnCDyTFOP9hbvbPvq9Y33vfscX6GQPPFusbx8rnj29deU5h55uK26K7OPMDSRF+ICnCDyRF+IGkCD+QFOEHkiL8QFJNx/ltL5R0j6QFkkLScETcZnu+pPslnShpq6RLI+JH3WsVrWg2jj9y6v3F+niT88Pv/9E1xfrRT/9bsY76TOfMv1/S5yNiqaSPSrrG9lJJN0gaiYglkkaq+wBmiKbhj4idEfFsdftNSZslHSdppaR11WrrJF3SrSYBdN4hvea3faKk0yRtkLQgInZWpdc08bIAwAwx7fDbfq+kByRdFxF7J9ciIjTxfsBU262xPWp7dJ/G2moWQOdMK/y252gi+N+IiAerxbtsD1b1QUm7p9o2IoYjYigihuZooBM9A+iApuG3bUl3S9ocEV+aVFovaXV1e7WkhzvfHoBumc4lvWdJukLSJtvPVctulHSLpL+zfZWkbZIu7U6LaObVW1c0rH3v1DuK2zYbyvvFb19drt/PUN5M1TT8EfGkpEaTrJ/f2XYA9Aqf8AOSIvxAUoQfSIrwA0kRfiApwg8kxVd3zwTLTy2WRy77i4a1cR1V3HZc5Sm2V33k6WJ9/fVnF+uzVjS+yvviD7xY3LZd39r24Ya1wUvK04NnwJkfSIrwA0kRfiApwg8kRfiBpAg/kBThB5LyxDdw9cY8z48zzVXAnVa8nv/yZtfzl//+sxpezd3+9s22nePZxfq+OFCsf/rlX29YGzv3teK2M9WGGNHe2FP+o1U48wNJEX4gKcIPJEX4gaQIP5AU4QeSIvxAUlzPfxhY9IdPNaxd8O3fbuuxd5x7ZLG+b8n/Feubz7urYa3Zdwlc+f3zivV/feWkYv3k66ecRAoVzvxAUoQfSIrwA0kRfiApwg8kRfiBpAg/kFTT6/ltL5R0j6QFkkLScETcZvtmSZ+R9Hq16o0R8WjpsbieH+iuQ7mefzof8tkv6fMR8aztoyU9Y/vxqvbliPjLVhsFUJ+m4Y+InZJ2VrfftL1Z0nHdbgxAdx3Sa37bJ0o6TdKGatG1tp+3vdb2MQ22WWN71PboPo211SyAzpl2+G2/V9IDkq6LiL2S7pS0WNIyTTwz+OJU20XEcEQMRcTQHA10oGUAnTCt8Nueo4ngfyMiHpSkiNgVEQciYlzS1yQt716bADqtafhtW9LdkjZHxJcmLR+ctNqnJL3Q+fYAdMt03u0/S9IVkjbZfq5adqOkVbaXaWL4b6ukq7vSIYCumM67/U9KU375enFMH0B/4xN+QFKEH0iK8ANJEX4gKcIPJEX4gaQIP5AU4QeSIvxAUoQfSIrwA0kRfiApwg8kRfiBpJp+dXdHd2a/LmnbpEXvl/TDnjVwaPq1t37tS6K3VnWytw9ExM9NZ8Wehv9dO7dHI2KotgYK+rW3fu1LordW1dUbT/uBpAg/kFTd4R+uef8l/dpbv/Yl0Vuraumt1tf8AOpT95kfQE1qCb/tC22/ZPtl2zfU0UMjtrfa3mT7OdujNfey1vZu2y9MWjbf9uO2t1S/p5wmrabebra9ozp2z9m+qKbeFtr+Z9vftf2i7c9Vy2s9doW+ajluPX/ab3u2pP+U9DFJ2yVtlLQqIr7b00YasL1V0lBE1D4mbPscSW9JuiciTqmW3SppT0TcUv3HeUxEXN8nvd0s6a26Z26uJpQZnDyztKRLJP2Wajx2hb4uVQ3HrY4z/3JJL0fEqxHxtqT7JK2soY++FxFPSNpz0OKVktZVt9dp4h9PzzXorS9ExM6IeLa6/aakd2aWrvXYFfqqRR3hP07SDybd367+mvI7JD1m+xnba+puZgoLqmnTJek1SQvqbGYKTWdu7qWDZpbum2PXyozXncYbfu92dkScLukTkq6pnt72pZh4zdZPwzXTmrm5V6aYWfon6jx2rc543Wl1hH+HpIWT7h9fLesLEbGj+r1b0kPqv9mHd70zSWr1e3fN/fxEP83cPNXM0uqDY9dPM17XEf6NkpbY/qDtIyRdJml9DX28i+251Rsxsj1X0sfVf7MPr5e0urq9WtLDNfbyU/pl5uZGM0ur5mPXdzNeR0TPfyRdpIl3/F+R9IU6emjQ1yJJ/1H9vFh3b5Lu1cTTwH2aeG/kKknHShqRtEXSP0ma30e9/Y2kTZKe10TQBmvq7WxNPKV/XtJz1c9FdR+7Ql+1HDc+4QckxRt+QFKEH0iK8ANJEX4gKcIPJEX4gaQIP5AU4QeS+n8qwVgO+Sle1wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f4ef60c7710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "index = 362\n",
    "\n",
    "x_test_prim = x_test[index]\n",
    "print(\"x_test_prim.shape: \",x_test_prim.shape)\n",
    "img_usable = np.expand_dims(x_test_prim, axis=0)\n",
    "img_to_show = np.reshape(x_test_prim, (28,28))\n",
    "plt.imshow(img_to_show)\n",
    "print(img_usable.shape)\n",
    "pred_prim = model.predict_classes(img_usable)\n",
    "print(\"pred_prim: \",pred_prim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 10)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
